{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:22.132572Z",
     "iopub.status.busy": "2022-10-03T13:35:22.132270Z",
     "iopub.status.idle": "2022-10-03T13:35:22.140049Z",
     "shell.execute_reply": "2022-10-03T13:35:22.139051Z",
     "shell.execute_reply.started": "2022-10-03T13:35:22.132541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:23.290120Z",
     "iopub.status.busy": "2022-10-03T13:35:23.289847Z",
     "iopub.status.idle": "2022-10-03T13:35:23.343488Z",
     "shell.execute_reply": "2022-10-03T13:35:23.342660Z",
     "shell.execute_reply.started": "2022-10-03T13:35:23.290088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>word_freq_receive</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_make</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.21</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word_freq_address  word_freq_all  word_freq_3d  word_freq_our  \\\n",
       "word_freq_make                                                                  \n",
       "0.00                         0.64           0.64           0.0           0.32   \n",
       "0.21                         0.28           0.50           0.0           0.14   \n",
       "0.06                         0.00           0.71           0.0           1.23   \n",
       "0.00                         0.00           0.00           0.0           0.63   \n",
       "0.00                         0.00           0.00           0.0           0.63   \n",
       "\n",
       "                word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "word_freq_make                                                         \n",
       "0.00                      0.00              0.00                0.00   \n",
       "0.21                      0.28              0.21                0.07   \n",
       "0.06                      0.19              0.19                0.12   \n",
       "0.00                      0.00              0.31                0.63   \n",
       "0.00                      0.00              0.31                0.63   \n",
       "\n",
       "                word_freq_order  word_freq_mail  word_freq_receive  ...  \\\n",
       "word_freq_make                                                      ...   \n",
       "0.00                       0.00            0.00               0.00  ...   \n",
       "0.21                       0.00            0.94               0.21  ...   \n",
       "0.06                       0.64            0.25               0.38  ...   \n",
       "0.00                       0.31            0.63               0.31  ...   \n",
       "0.00                       0.31            0.63               0.31  ...   \n",
       "\n",
       "                char_freq_;  char_freq_(  char_freq_[  char_freq_!  \\\n",
       "word_freq_make                                                       \n",
       "0.00                   0.00        0.000          0.0        0.778   \n",
       "0.21                   0.00        0.132          0.0        0.372   \n",
       "0.06                   0.01        0.143          0.0        0.276   \n",
       "0.00                   0.00        0.137          0.0        0.137   \n",
       "0.00                   0.00        0.135          0.0        0.135   \n",
       "\n",
       "                char_freq_$  char_freq_#  capital_run_length_average  \\\n",
       "word_freq_make                                                         \n",
       "0.00                  0.000        0.000                       3.756   \n",
       "0.21                  0.180        0.048                       5.114   \n",
       "0.06                  0.184        0.010                       9.821   \n",
       "0.00                  0.000        0.000                       3.537   \n",
       "0.00                  0.000        0.000                       3.537   \n",
       "\n",
       "                capital_run_length_longest  capital_run_length_total  spam  \n",
       "word_freq_make                                                              \n",
       "0.00                                    61                       278     1  \n",
       "0.21                                   101                      1028     1  \n",
       "0.06                                   485                      2259     1  \n",
       "0.00                                    40                       191     1  \n",
       "0.00                                    40                       191     1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv( \"spambase.csv\", index_col = 0)\n",
    "\n",
    "# Display the dataframe\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:23.790986Z",
     "iopub.status.busy": "2022-10-03T13:35:23.790262Z",
     "iopub.status.idle": "2022-10-03T13:35:23.797675Z",
     "shell.execute_reply": "2022-10-03T13:35:23.796658Z",
     "shell.execute_reply.started": "2022-10-03T13:35:23.790947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 57)\n"
     ]
    }
   ],
   "source": [
    "print(spam.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data includes 4601 e-mails (rows) and 57 features (columns). Its features are characterized as follows:\n",
    "\n",
    "* **word_freq_address** - percentage of words in the e-mail that match ADDRESS.\n",
    "* **char_freq_#**  - percentage of characters in the e-mail that match the symbol '#'.\n",
    "* **capital_run_length_average** - average lenth of uninterrupted sequences of capital letters.\n",
    "* **capital_run_length_longest** - length of longest uninterrupted sequence of catipal letters.\n",
    "* **capital_run_length_total** - total number of capital letters in the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:24.724882Z",
     "iopub.status.busy": "2022-10-03T13:35:24.724294Z",
     "iopub.status.idle": "2022-10-03T13:35:24.745739Z",
     "shell.execute_reply": "2022-10-03T13:35:24.745024Z",
     "shell.execute_reply.started": "2022-10-03T13:35:24.724838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 4601 entries, 0.0 to 0.0\n",
      "Data columns (total 57 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_address           4601 non-null   float64\n",
      " 1   word_freq_all               4601 non-null   float64\n",
      " 2   word_freq_3d                4601 non-null   float64\n",
      " 3   word_freq_our               4601 non-null   float64\n",
      " 4   word_freq_over              4601 non-null   float64\n",
      " 5   word_freq_remove            4601 non-null   float64\n",
      " 6   word_freq_internet          4601 non-null   float64\n",
      " 7   word_freq_order             4601 non-null   float64\n",
      " 8   word_freq_mail              4601 non-null   float64\n",
      " 9   word_freq_receive           4601 non-null   float64\n",
      " 10  word_freq_will              4601 non-null   float64\n",
      " 11  word_freq_people            4601 non-null   float64\n",
      " 12  word_freq_report            4601 non-null   float64\n",
      " 13  word_freq_addresses         4601 non-null   float64\n",
      " 14  word_freq_free              4601 non-null   float64\n",
      " 15  word_freq_business          4601 non-null   float64\n",
      " 16  word_freq_email             4601 non-null   float64\n",
      " 17  word_freq_you               4601 non-null   float64\n",
      " 18  word_freq_credit            4601 non-null   float64\n",
      " 19  word_freq_your              4601 non-null   float64\n",
      " 20  word_freq_font              4601 non-null   float64\n",
      " 21  word_freq_000               4601 non-null   float64\n",
      " 22  word_freq_money             4601 non-null   float64\n",
      " 23  word_freq_hp                4601 non-null   float64\n",
      " 24  word_freq_hpl               4601 non-null   float64\n",
      " 25  word_freq_george            4601 non-null   float64\n",
      " 26  word_freq_650               4601 non-null   float64\n",
      " 27  word_freq_lab               4601 non-null   float64\n",
      " 28  word_freq_labs              4601 non-null   float64\n",
      " 29  word_freq_telnet            4601 non-null   float64\n",
      " 30  word_freq_857               4601 non-null   float64\n",
      " 31  word_freq_data              4601 non-null   float64\n",
      " 32  word_freq_415               4601 non-null   float64\n",
      " 33  word_freq_85                4601 non-null   float64\n",
      " 34  word_freq_technology        4601 non-null   float64\n",
      " 35  word_freq_1999              4601 non-null   float64\n",
      " 36  word_freq_parts             4601 non-null   float64\n",
      " 37  word_freq_pm                4601 non-null   float64\n",
      " 38  word_freq_direct            4601 non-null   float64\n",
      " 39  word_freq_cs                4601 non-null   float64\n",
      " 40  word_freq_meeting           4601 non-null   float64\n",
      " 41  word_freq_original          4601 non-null   float64\n",
      " 42  word_freq_project           4601 non-null   float64\n",
      " 43  word_freq_re                4601 non-null   float64\n",
      " 44  word_freq_edu               4601 non-null   float64\n",
      " 45  word_freq_table             4601 non-null   float64\n",
      " 46  word_freq_conference        4601 non-null   float64\n",
      " 47  char_freq_;                 4601 non-null   float64\n",
      " 48  char_freq_(                 4601 non-null   float64\n",
      " 49  char_freq_[                 4601 non-null   float64\n",
      " 50  char_freq_!                 4601 non-null   float64\n",
      " 51  char_freq_$                 4601 non-null   float64\n",
      " 52  char_freq_#                 4601 non-null   float64\n",
      " 53  capital_run_length_average  4601 non-null   float64\n",
      " 54  capital_run_length_longest  4601 non-null   int64  \n",
      " 55  capital_run_length_total    4601 non-null   int64  \n",
      " 56  spam                        4601 non-null   int64  \n",
      "dtypes: float64(54), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "# show information about the data\n",
    "spam.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has 1 categorical, and 56 continuous variables.    \n",
    "\n",
    "The data doesn't have missing values.\n",
    "\n",
    "ðŸ“Œ Email **spam:** yes=1, no=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:26.131446Z",
     "iopub.status.busy": "2022-10-03T13:35:26.131154Z",
     "iopub.status.idle": "2022-10-03T13:35:26.162174Z",
     "shell.execute_reply": "2022-10-03T13:35:26.161313Z",
     "shell.execute_reply.started": "2022-10-03T13:35:26.131415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>word_freq_receive</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_make</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.203</td>\n",
       "      <td>2.430</td>\n",
       "      <td>121</td>\n",
       "      <td>666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.722</td>\n",
       "      <td>20</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.729</td>\n",
       "      <td>55</td>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word_freq_address  word_freq_all  word_freq_3d  word_freq_our  \\\n",
       "word_freq_make                                                                  \n",
       "0.0                           0.0           1.02           0.0           0.00   \n",
       "0.0                           0.0           0.23           0.0           0.46   \n",
       "0.0                           0.0           0.36           0.0           0.36   \n",
       "0.0                           0.0           0.00           0.0           0.00   \n",
       "0.0                           0.0           0.56           0.0           0.08   \n",
       "\n",
       "                word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "word_freq_make                                                         \n",
       "0.0                       0.00               0.0                 0.0   \n",
       "0.0                       0.00               0.0                 0.0   \n",
       "0.0                       0.00               0.0                 0.0   \n",
       "0.0                       0.00               0.0                 0.0   \n",
       "0.0                       0.16               0.0                 0.0   \n",
       "\n",
       "                word_freq_order  word_freq_mail  word_freq_receive  ...  \\\n",
       "word_freq_make                                                      ...   \n",
       "0.0                        0.00            0.00                0.0  ...   \n",
       "0.0                        0.23            0.00                0.0  ...   \n",
       "0.0                        0.00            0.00                0.0  ...   \n",
       "0.0                        0.00            0.00                0.0  ...   \n",
       "0.0                        0.00            0.16                0.0  ...   \n",
       "\n",
       "                char_freq_;  char_freq_(  char_freq_[  char_freq_!  \\\n",
       "word_freq_make                                                       \n",
       "0.0                   0.000        0.550        0.000         0.00   \n",
       "0.0                   0.000        0.113        0.000         0.09   \n",
       "0.0                   0.279        0.767        0.139         0.00   \n",
       "0.0                   0.000        0.000        0.000         0.00   \n",
       "0.0                   0.164        0.505        0.000         0.01   \n",
       "\n",
       "                char_freq_$  char_freq_#  capital_run_length_average  \\\n",
       "word_freq_make                                                         \n",
       "0.0                   0.000        0.000                       1.333   \n",
       "0.0                   0.000        0.203                       2.430   \n",
       "0.0                   0.000        0.000                       3.722   \n",
       "0.0                   0.000        0.000                       1.250   \n",
       "0.0                   0.021        0.000                       2.729   \n",
       "\n",
       "                capital_run_length_longest  capital_run_length_total  spam  \n",
       "word_freq_make                                                              \n",
       "0.0                                      5                        28     0  \n",
       "0.0                                    121                       666     0  \n",
       "0.0                                     20                       268     0  \n",
       "0.0                                      2                         5     0  \n",
       "0.0                                     55                      1122     0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset into training (70%) and testing (30%)\n",
    "spam_train, spam_test = split(spam, train_size = 0.7, random_state = 1313) \n",
    "spam_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:26.563908Z",
     "iopub.status.busy": "2022-10-03T13:35:26.563333Z",
     "iopub.status.idle": "2022-10-03T13:35:26.571688Z",
     "shell.execute_reply": "2022-10-03T13:35:26.570748Z",
     "shell.execute_reply.started": "2022-10-03T13:35:26.563871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create target\n",
    "X = spam_train.drop(['spam'], axis = 1)\n",
    "y = spam_train['spam']\n",
    "\n",
    "X_test = spam_test.drop(['spam'], axis = 1)\n",
    "y_test = spam_test['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default metric (Euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:27.980217Z",
     "iopub.status.busy": "2022-10-03T13:35:27.979940Z",
     "iopub.status.idle": "2022-10-03T13:35:28.145413Z",
     "shell.execute_reply": "2022-10-03T13:35:28.144680Z",
     "shell.execute_reply.started": "2022-10-03T13:35:27.980178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8680124223602484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Create KNN Classifier model for k = 5\n",
    "k = 5\n",
    "spam_clf = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "# Train the model using the training sets\n",
    "spam_clf.fit(X, y)\n",
    "\n",
    "print(spam_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:29.040506Z",
     "iopub.status.busy": "2022-10-03T13:35:29.040132Z",
     "iopub.status.idle": "2022-10-03T13:35:29.203929Z",
     "shell.execute_reply": "2022-10-03T13:35:29.203173Z",
     "shell.execute_reply.started": "2022-10-03T13:35:29.040466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Not-spam  Spam\n",
      "Not-spam      1763   194\n",
      "Spam           231  1032\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1957\n",
      "           1       0.84      0.82      0.83      1263\n",
      "\n",
      "    accuracy                           0.87      3220\n",
      "   macro avg       0.86      0.86      0.86      3220\n",
      "weighted avg       0.87      0.87      0.87      3220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for train dataset\n",
    "train_pred_1 = spam_clf.predict(X)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true = y, y_pred = train_pred_1)\n",
    "\n",
    "print(pd.DataFrame(cm, index = ['Not-spam', 'Spam'], columns = ['Not-spam', 'Spam']))\n",
    "print('-----------------------------------------------------')\n",
    "print(classification_report(y_true = y, y_pred = train_pred_1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T13:35:47.592093Z",
     "iopub.status.busy": "2022-10-03T13:35:47.591826Z",
     "iopub.status.idle": "2022-10-03T13:35:47.709932Z",
     "shell.execute_reply": "2022-10-03T13:35:47.708772Z",
     "shell.execute_reply.started": "2022-10-03T13:35:47.592063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9226708074534161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create Logistic Regression Classifier model\n",
    "spam_clf = LogisticRegression()\n",
    "\n",
    "# Fit the model using the training set\n",
    "spam_clf.fit(X, y)\n",
    "\n",
    "print(spam_clf.score(X, y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
